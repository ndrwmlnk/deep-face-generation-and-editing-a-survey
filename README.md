## ðŸ“– Face Generation and Editing with StyleGAN: A Survey

Survey link: https://arxiv.org/abs/2212.09102

```
@article{melnik2022face,
  title={Face Generation and Editing with StyleGAN: A Survey},
  author={Melnik, Andrew and Miasayedzenkau, Maksim and Makarovets, Dzianis and Pirshtuk, Dzianis and Akbulut, Eren and Holzmann, Dennis and Renusch, Tarek and Reichert, Gustav and Ritter, Helge},
  journal={arXiv preprint arXiv:2212.09102},
  year={2022}
}
```

---

[Papers](#papers)

- [2023](#2023)
- [2022](#2022)
- [2021](#2021)
- [2020](#2020)
- [2019](#2019)
- [2018](#2018)
- [2017](#2017)
- [2016](#2016)
<!-- - [2015](#2015)
- [2014](#2014)
- [2012](#2012)
 -->
[Web Applications](#web-applications)

[Datasets](#datasets)

<!-- -   [Neural Network Architectures for Generation of Faces](#neural-network-architectures-for-generation-of-faces)
-   [Similarity of Faces and Loses For Training](#similarity-of-faces-and-loses-for-training)
-   [The Latent Space](#the-latent-space)
-   [Image Inversion to a Latent Space of StyleGAN](#image-inversion-to-a-latent-space-of-stylegan)
-   [Editing of Generated Images ](#editing-of-generated-images)
-   [Finding control parameters in the latent space - Editing approaches](#finding-control-parameters-in-the-latent-space)
-   [Deep Fake](#deep-fake)
-   [Deblurring](#deblurring)
 -->

---

### Papers
## 2023 
<br />

ðŸ“„<b> LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis </b> 
[[Paper]](https://arxiv.org/abs/2301.04604)  [[Project]](https://zhujiapeng.github.io/linkgan/) [[Github]](https://github.com/zhujiapeng/linkgan) arxiv
<sub><sup>Jiapeng Zhu, Ceyuan Yang, Yujun Shen, Zifan Shi, Deli Zhao, Qifeng Chen</sup></sub><br />

ðŸ“„<b> SLI-pSp: Injecting Multi-Scale Spatial Layout in pSp </b> 
[[Paper]](https://openaccess.thecvf.com/content/WACV2023/papers/Mathur_SLI-pSp_Injecting_Multi-Scale_Spatial_Layout_in_pSp_WACV_2023_paper) WACV
<sub><sup>Aradhya Neeraj Mathur, Anish Madan, Ojaswa Sharma</sup></sub><br />

## 2022 
<br />

ðŸ“„<b> Face Generation and Editing with StyleGAN: A Survey </b> 
[[Paper]](https://arxiv.org/abs/2212.09102) arxiv
<sub><sup>Andrew Melnik, Maksim Miasayedzenkau, Dzianis Makarovets, Dzianis Pirshtuk, Eren Akbulut, Dennis Holzmann, Tarek Renusch, Gustav Reichert, Helge Ritter</sup></sub><br />

ðŸ“„<b> 3D Cartoon Face Generation with Controllable Expressions from a Single GAN Image </b> 
[[Paper]](https://arxiv.org/abs/2207.14425) arxiv
<sub><sup>Hao Wang, Guosheng Lin, Steven C. H. Hoi, Chunyan Miao</sup></sub><br />

ðŸ“„<b> Faces: AI Blitz XIII Solutions </b> 
[[Paper]](https://arxiv.org/abs/2204.01081)  [[Github]](https://github.com/ndrwmlnk/ai-blitz-xiii) arxiv
<sub><sup>Andrew Melnik, Eren Akbulut, Jannik Sheikh, Kira Loos, Michael Buettner, Tobias Lenze</sup></sub><br />

ðŸ“„<b> MyStyle: A Personalized Generative Prior </b> 
[[Paper]](https://arxiv.org/abs/2203.17272) [[Github]](https://mystyle-personalized-prior.github.io/) [[Video]](https://www.youtube.com/watch?v=axWo_9Gt47o) arxiv
<sub><sup>Yotam Nitzan, Kfir Aberman, Qiurui He, Orly Liba, Michal Yarom, Yossi Gandelsman, Inbar Mosseri, Yael Pritch, Daniel Cohen-or</sup></sub><br />

ðŸ“„<b> Third Time's the Charm? Image and Video Editing with StyleGAN3 </b> 
[[Paper]](https://arxiv.org/abs/2201.13433)  [[Github]](https://github.com/yuval-alaluf/stylegan3-editing) arxiv
<sub><sup>Yuval Alaluf, Or Patashnik, Zongze Wu, Asif Zamir, Eli Shechtman, Dani Lischinski, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> E2Style: Improve the Efficiency and Effectiveness of StyleGAN Inversion </b> 
[[Paper]](https://arxiv.org/abs/2201.13433)  [[Github]](https://github.com/wty-ustc/e2style) IEEE Transactions on Image Processing
<sub><sup>Tianyi Wei, Dongdong Chen, Wenbo Zhou, Jing Liao, Weiming Zhang, Lu Yuan, Gang Hua, Nenghai Yu</sup></sub><br />

ðŸ“„<b> Unsupervised face frontalization using disentangled representation-learning CycleGAN </b> 
[[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S1077314222001096) Computer Vision and Image Understanding
<sub><sup>Yanfei Liu Junhua Chen</sup></sub><br />

## 2021 
<br />

ðŸ“„<b> HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing </b> 
[[Paper]](https://arxiv.org/abs/2111.15666) [[Github]](https://github.com/yuval-alaluf/hyperstyle) [[Video]](https://www.youtube.com/watch?v=_sbXmLY2jMw) CVPR
<sub><sup>Yuval Alaluf, Omer Tov, Ron Mokady, Rinon Gal, Amit H. Bermano</sup></sub><br />

ðŸ“„<b> Fine-Tuning StyleGAN2 For Cartoon Face Generation </b> 
[[Paper]](https://arxiv.org/abs/2106.12445) arxiv
<sub><sup>Jihye Back</sup></sub><br />

ðŸ“„<b> Pivotal Tuning for Latent-based Editing of Real Images </b> 
[[Paper]](https://arxiv.org/abs/2106.05744)  [[Github]](https://github.com/danielroich/PTI) ACM
<sub><sup>Daniel Roich, Ron Mokady, Amit H. Bermano, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> Transforming the Latent Space of StyleGAN for Real Face Editing </b> 
[[Paper]](https://arxiv.org/abs/2105.14230)  [[Github]](https://github.com/AnonSubm2021/TransStyleGAN) arxiv
<sub><sup>Heyi Li, Jinlong Liu, Xinyu Zhang, Yunzhi Bai, Huayan Wang, Klaus Mueller</sup></sub><br />

ðŸ“„<b> One Shot Face Swapping on Megapixels </b> 
[[Paper]](https://arxiv.org/abs/2105.04932)  [[Github]](https://github.com/zyainfal/One-Shot-Face-Swapping-on-Megapixels) CVPR
<sub><sup>Yuhao Zhu, Qi Li, Jian Wang, Chengzhong Xu, Zhenan Sun</sup></sub><br />

ðŸ“„<b> ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement </b> 
[[Paper]](https://arxiv.org/abs/2104.02699) [[Github]](https://github.com/yuval-alaluf/restyle-encoder) [[Video]](https://www.youtube.com/watch?v=6pGzLECSIWM) ICCV
<sub><sup>Yuval Alaluf, Or Patashnik, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> Designing an Encoder for StyleGAN Image Manipulation </b> 
[[Paper]](https://arxiv.org/abs/2102.02766) [[Github]](https://github.com/omertov/encoder4editing) [[Video]](https://dl.acm.org/doi/10.1145/3450626.3459838) arxiv
<sub><sup>Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery </b> 
[[Paper]](https://arxiv.org/abs/2103.17249) [[Github]](https://github.com/orpatashnik/StyleCLIP) [[Video]](https://www.youtube.com/watch?v=5icI0NgALnQ) IEEE/CVF
<sub><sup>Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, Dani Lischinski</sup></sub><br />

ðŸ“„<b> StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators </b> 
[[Paper]](https://arxiv.org/abs/2108.00946)  [[Github]](https://github.com/rinongal/StyleGAN-nada) CoRR
<sub><sup>Rinon Gal, Or Patashnik, Haggai Maron, Gal Chechik, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> Alias-Free Generative Adversarial Networks </b> 
[[Paper]](https://arxiv.org/abs/2106.12423) [[Github]](https://github.com/NVlabs/stylegan3) [[Video]](https://nvlabs-fi-cdn.nvidia.com/stylegan3/videos/) NeurIPS
<sub><sup>Tero Karras, Miika Aittala, Samuli Laine, Erik HÃƒÂ¤rkÃƒÂ¶nen, Janne Hellsten, Jaakko Lehtinen, Timo Aila</sup></sub><br />

ðŸ“„<b> Normalized Avatar Synthesis Using StyleGAN and Perceptual Refinement </b> 
[[Paper]](https://arxiv.org/abs/2106.11423)  [[Video]](https://www.youtube.com/watch?v=V9r_jOiGX84) IEEE/CVF
<sub><sup>Huiwen Luo, Koki Nagano, Han-Wei Kung, Mclean Goldwhite, Qingguo Xu, Zejian Wang, Lingyu Wei, Liwen Hu, Hao Li</sup></sub><br />

ðŸ“„<b> Learning Transferable Visual Models From Natural Language Supervision </b> 
[[Paper]](https://arxiv.org/abs/2103.00020)  [[Github]](https://github.com/openai/CLIP) PMLR
<sub><sup>Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever</sup></sub><br />

ðŸ“„<b> StyleCariGAN: Caricature Generation via StyleGAN Feature Map Modulation </b> 
[[Paper]](https://arxiv.org/abs/2107.04331) [[Github]](https://github.com/wonjongg/StyleCariGAN) [[Video]](https://www.youtube.com/watch?v=kpHbGOlI-BU&feature=youtu.be) ACM
<sub><sup>Wonjong Jang, Gwangjin Ju, Yucheol Jung, Jiaolong Yang, Xin Tong, Seungyong Lee</sup></sub><br />

ðŸ“„<b> Towards Real-World Blind Face Restoration with Generative Facial Prior </b> 
[[Paper]](https://arxiv.org/abs/2101.04061)  [[Github]](https://github.com/TencentARC/GFPGAN) IEEE/CVF
<sub><sup>Xintao Wang, Yu Li, Honglun Zhang, Ying Shan</sup></sub><br />

ðŸ“„<b> Positional Encoding as Spatial Inductive Bias in GANs </b> 
[[Paper]](https://arxiv.org/abs/2012.05217) IEEE/CVF 2021
<sub><sup>Rui Xu, Xintao Wang, Kai Chen, Bolei Zhou, Chen Change Loy</sup></sub><br />

ðŸ“„<b> Designing an Encoder for StyleGAN Image Manipulation </b> 
[[Paper]](https://arxiv.org/abs/2102.02766)  [[Github]](https://github.com/omertov/encoder4editing) ACM
<sub><sup>Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation </b> 
[[Paper]](https://arxiv.org/abs/2110.11728)  [[Github]](https://github.com/onion-liu/BlendGAN) Advances in Neural Information Processing Systems
<sub><sup>Mingcong Liu, Qiang Li, Zekui Qin, Guoxin Zhang, Pengfei Wan, Wen Zheng</sup></sub><br />

ðŸ“„<b> StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation </b> 
[[Paper]](https://arxiv.org/abs/2011.12799) [[Github]](https://github.com/betterze/StyleSpace) [[Video]](https://www.youtube.com/watch?v=U7qRotRGr1w&feature=youtu.be) CVPR
<sub><sup>Zongze Wu, Dani Lischinski, Eli Shechtman</sup></sub><br />

## 2020
<br/>

ðŸ“„<b> Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation </b> 
[[Paper]](https://arxiv.org/abs/2008.00951) [[Github]](https://github.com/eladrich/pixel2style2pixel) [[Video]](https://www.youtube.com/watch?v=bfvSwhqsTgM) CVPR
<sub><sup>Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> Training Generative Adversarial Networks with Limited Data </b> 
[[Paper]](https://arxiv.org/abs/2006.06676)  [[Github]](https://github.com/NVlabs/stylegan2-ada) arxiv
<sub><sup>Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, Timo Aila</sup></sub><br />

ðŸ“„<b> The Creation and Detection of Deepfakes: A Survey </b> 
[[Paper]](https://arxiv.org/abs/2004.11138) CSUR
<sub><sup>Yisroel Mirsky, Wenke Lee</sup></sub><br />

ðŸ“„<b> StyleRig: Rigging StyleGAN for 3D Control over Portrait Images </b> 
[[Paper]](https://arxiv.org/abs/2004.00121) IEEE/CVF
<sub><sup>Ayush Tewari, Mohamed Elgharib, Gaurav Bharaj, Florian Bernard, Hans-Peter Seidel, Patrick PÃƒÂ©rez, Michael ZollhÃƒÂ¶fer, Christian Theobalt</sup></sub><br />

ðŸ“„<b> Media Forensics and DeepFakes: an overview </b> 
[[Paper]](https://arxiv.org/abs/2001.06564) IEEE Journal of Selected Topics in Signal Processing
<sub><sup>Luisa Verdoliva</sup></sub><br />

ðŸ“„<b> Neural Head Reenactment with Latent Pose Descriptors </b> 
[[Paper]](https://arxiv.org/abs/2004.12000)  [[Github]](https://github.com/shrubb/latent-pose-reenactment) CVPR
<sub><sup>Egor Burkov, Igor Pasechnik, Artur Grigorev, Victor Lempitsky</sup></sub><br />

ðŸ“„<b> GAN Compression: Efficient Architectures for Interactive Conditional GANs </b> 
[[Paper]](https://arxiv.org/abs/2003.08936) [[Github]](https://github.com/mit-han-lab/gan-compression) [[Video]](https://www.youtube.com/playlist?list=PL80kAHvQbh-r5R8UmXhQK1ndqRvPNw_ex) CVPR
<sub><sup>Muyang Li, Ji Lin, Yaoyao Ding, Zhijian Liu, Jun-Yan Zhu, Song Han</sup></sub><br />

ðŸ“„<b> StyleGAN2 Distillation for Feed-forward Image Manipulation </b> 
[[Paper]](https://arxiv.org/abs/2003.03581)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) Springer
<sub><sup>Yuri Viazovetskyi, Vladimir Ivashkin, Evgeny Kashin </sup></sub><br />

ðŸ“„<b> Collaborative Learning for Faster StyleGAN Embedding </b> 
[[Paper]](https://arxiv.org/abs/2007.01758)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) arxiv
<sub><sup>Shanyan Guan, Ying Tai, Bingbing Ni, Feida Zhu, Feiyue Huang, Xiaokang Yang</sup></sub><br />

ðŸ“„<b> In-Domain GAN Inversion for Real Image Editing </b> 
[[Paper]](https://arxiv.org/abs/2004.00049)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) arxiv
<sub><sup>Jiapeng Zhu, Yujun Shen, Deli Zhao, Bolei Zhou</sup></sub><br />

ðŸ“„<b> Interpreting the Latent Space of GANs for Semantic Face Editing </b> 
[[Paper]](https://arxiv.org/abs/1907.10786) CVPR
<sub><sup>Yujun Shen, Jinjin Gu, Xiaoou Tang, Bolei Zhou</sup></sub><br />

ðŸ“„<b> GANSpace: Discovering Interpretable GAN Controls </b> 
[[Paper]](https://arxiv.org/abs/2004.02546)  [[Github]](https://github.com/harskish/ganspace) Advances in Neural Information Processing Systems
<sub><sup>Erik HÃƒÂ¤rkÃƒÂ¶nen, Aaron Hertzmann, Jaakko Lehtinen, Sylvain Paris</sup></sub><br />

ðŸ“„<b> Resolution Dependent GAN Interpolation for Controllable Image Synthesis Between Domains </b> 
[[Paper]](https://arxiv.org/abs/2010.05334) arxiv
<sub><sup>Justin N. M. Pinkney, Doron Adler</sup></sub><br />

ðŸ“„<b> Advancing High Fidelity Identity Swapping for Forgery Detection </b> 
[[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Advancing_High_Fidelity_Identity_Swapping_for_Forgery_Detection_CVPR_2020_paper.html) CVPR
<sub><sup>Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, Fang Wen</sup></sub><br />

## 2019
<br />

ðŸ“„<b> Analyzing and Improving the Image Quality of StyleGAN </b> 
[[Paper]](https://arxiv.org/abs/1912.04958) [[Github]](https://github.com/NVlabs/stylegan2) [[Video]](https://www.youtube.com/watch?v=c-NJtV9Jvp0) IEEE/CVF
<sub><sup>Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila</sup></sub><br />

ðŸ“„<b> Unconstrained Facial Expression Transfer using Style-based Generator </b> 
[[Paper]](https://arxiv.org/abs/1912.06253) arxiv
<sub><sup>Chao Yang, Ser-Nam Lim</sup></sub><br />

ðŸ“„<b> Image2StyleGAN++: How to Edit the Embedded Images? </b> 
[[Paper]](https://arxiv.org/abs/1911.11544)  [[Video]](https://www.youtube.com/watch?v=kEKVSMTTQEI) IEEE/CVF
<sub><sup>Rameen Abdal, Yipeng Qin, Peter Wonka</sup></sub><br />

ðŸ“„<b> Deep Learning for Deepfakes Creation and Detection: A Survey </b> 
[[Paper]](https://arxiv.org/abs/1909.11573) arxiv
<sub><sup>Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Dung Tien Nguyen, Duc Thanh Nguyen, Thien Huynh-The, Saeid Nahavandi, Thanh Tam Nguyen, Quoc-Viet Pham, Cuong M. Nguyen</sup></sub><br />

ðŸ“„<b> Mining Audio, Text and Visual Information for Talking Face Generation </b> 
[[Paper]](https://ieeexplore.ieee.org/document/8970886) ICDM
<sub><sup>L. Yu, J. Yu, and Q. Ling</sup></sub><br />

ðŸ“„<b> FReeNet: Multi-Identity Face Reenactment </b> 
[[Paper]](https://arxiv.org/abs/1905.11805) arxiv
<sub><sup>Jiangning Zhang, Xianfang Zeng, Mengmeng Wang, Yusu Pan, Liang Liu, Yong Liu, Yu Ding, Changjie Fan</sup></sub><br />

## 2018
<br />

ðŸ“„<b>  A Style-Based Generator Architecture for Generative Adversarial Networks </b> 
[[Paper]](https://arxiv.org/abs/1812.04948) [[Github]](https://github.com/NVlabs/stylegan) [[Video]](https://youtu.be/kSLJriaOumA) IEEE/CVF
<sub><sup>Tero Karras, Samuli Laine, Timo Aila </sup></sub><br />

ðŸ“„<b> Video-to-Video Synthesis </b> 
[[Paper]](https://arxiv.org/abs/1808.06601) [[Github]](https://github.com/NVIDIA/vid2vid) [[Video]](https://www.youtube.com/watch?v=GrP_aOSXt5U) NeurIPS
<sub><sup>Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Guilin Liu, Andrew Tao, Jan Kautz, Bryan Catanzaro</sup></sub><br />

ðŸ“„<b> End-to-End Speech-Driven Facial Animation with Temporal GANs </b> 
[[Paper]](https://arxiv.org/abs/1805.09313) BMVC
<sub><sup>Konstantinos Vougioukas, Stavros Petridis, Maja Pantic </sup></sub><br />

ðŸ“„<b> Talking Face Generation by Conditional Recurrent Adversarial Network </b> 
[[Paper]](https://arxiv.org/abs/1804.04786)  [[Github]](https://github.com/susanqq/Talking_Face_Generation) arxiv
<sub><sup>Yang Song, Jingwen Zhu, Dawei Li, Xiaolong Wang, Hairong Qi</sup></sub><br />

ðŸ“„<b> Unsupervised Depth Estimation, 3D Face Rotation and Replacement </b> 
[[Paper]](https://arxiv.org/abs/1803.09202)  [[Github]](https://github.com/joelmoniz/DepthNets) NeurIPS
<sub><sup>Tero Karras, Samuli Laine, Timo Aila </sup></sub><br />

ðŸ“„<b> ArcFace: Additive Angular Margin Loss for Deep Face Recognition </b> 
[[Paper]](https://arxiv.org/abs/1801.07698)  [[Github]](https://github.com/deepinsight/insightface) IEEE/CVF
<sub><sup>Jiankang Deng, Jia Guo, Jing Yang, Niannan Xue, Irene Kotsia, Stefanos Zafeiriou</sup></sub><br />

ðŸ“„<b> The Unreasonable Effectiveness of Deep Features as a Perceptual Metric </b> 
[[Paper]](https://arxiv.org/abs/1801.03924)  [[Github]](https://github.com/richzhang/PerceptualSimilarity) CVPR
<sub><sup>Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, Oliver Wang</sup></sub><br />

ðŸ“„<b> Photorealistic Monocular Gaze Redirection Using Machine Learning </b> 
[[Paper]](https://ieeexplore.ieee.org/document/8010348) IEEE
<sub><sup>D. Kononenko, Y. Ganin, D. Sungatullina, and V. Lempitsky</sup></sub><br />

## 2017
<br />

ðŸ“„<b> The Perception-Distortion Tradeoff </b> 
[[Paper]](https://arxiv.org/abs/1711.06077) IEEE/CVPR
<sub><sup>Yochai Blau, Tomer Michaeli</sup></sub><br />

ðŸ“„<b> Progressive Growing of GANs for Improved Quality, Stability, and Variation </b> 
[[Paper]](https://arxiv.org/abs/1710.10196)  [[Github]](https://github.com/tkarras/progressive_growing_of_gans) ICLR
<sub><sup>Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen</sup></sub><br />

ðŸ“„<b> MoCoGAN: Decomposing Motion and Content for Video Generation </b> 
[[Paper]](https://arxiv.org/abs/1707.04993)  [[Github]](https://github.com/sergeytulyakov/mocogan) IEEE/CVF
<sub><sup>Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, Jan Kautz</sup></sub><br />

ðŸ“„<b> GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium </b> 
[[Paper]](https://arxiv.org/abs/1706.08500)  [[Github]](https://github.com/bioinf-jku/TTUR) Advances in neural information processing systems
<sub><sup>Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter</sup></sub><br />

ðŸ“„<b> Representation Learning by Rotating Your Faces </b> 
[[Paper]](https://arxiv.org/abs/1705.11136) IEEE Transactions on Pattern Analysis and Machine Intelligence
<sub><sup>Luan Tran, Xi Yin, Xiaoming Liu</sup></sub><br />

ðŸ“„<b> On Convergence and Stability of GANs </b> 
[[Paper]](https://arxiv.org/abs/1705.07215)  [[Github]](https://github.com/kodalinaveen3/DRAGAN) arxiv
<sub><sup>Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira</sup></sub><br />

ðŸ“„<b> Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization </b> 
[[Paper]](https://arxiv.org/abs/1703.06868)  [[Github]](https://github.com/xunhuang1995/AdaIN-style) ICCV
<sub><sup>Xun Huang, Serge Belongie</sup></sub><br />

ðŸ“„<b> Precise Recovery of Latent Vectors from Generative Adversarial Networks </b> 
[[Paper]](https://arxiv.org/abs/1702.04782) arxiv
<sub><sup>Zachary C. Lipton, Subarna Tripathi</sup></sub><br />

ðŸ“„<b> Automated face swapping and its detection </b> 
[[Paper]](https://ieeexplore.ieee.org/abstract/document/8124497) ICSIP
<sub><sup>Y. Zhang, L. Zheng, and V. L. L. Thing</sup></sub><br />

ðŸ“„<b> Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks </b> 
[[Paper]](https://arxiv.org/abs/1703.10593)  [[Github]](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) CoRR
<sub><sup>Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros</sup></sub><br />

## 2016
<br />

ðŸ“„<b> Perceptual Losses for Real-Time Style Transfer and Super-Resolution </b> 
[[Paper]](https://arxiv.org/abs/1603.08155) Springer
<sub><sup>Justin Johnson, Alexandre Alahi, Li Fei-Fei</sup></sub><br />

ðŸ“„<b>  Face2Face: Real-time Face Capture and Reenactment of RGB Videos </b> 
[[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/html/Thies_Face2Face_Real-Time_Face_CVPR_2016_paper.html) IEEE conference on computer vision and pattern recognition
<sub><sup>Justus Thies, Michael ZollhÃƒÂ¶fer, Marc Stamminger, Christian Theobalt, Matthias NieÃƒÂŸner</sup></sub><br />


---

<!-- ### Application Papers StyleGAN

**Towards real-world blind face restoration with generative facial prior**

| <img src='/Images/gfpgan.png' style='height: 225px'>
|:--:|
| GFP-GAN Compared to Other Approaches and GT |

Paper: https://arxiv.org/abs/2101.04061 <br/>
Code: https://github.com/TencentARC/GFPGAN <br/>

**MyStyle: A Personalized Generative Prior**

| <img src='/Images/mystyle.png' style='height: 200px'> | <img src='/Images/mystyle2.png' style='height: 200px'> |
| :---------------------------------------------------: | :----------------------------------------------------: |
|                    Solarized dark                     |                    Solarized Ocean                     |

Paper: https://arxiv.org/abs/2203.17272 <br/>
Project: https://mystyle-personalized-prior.github.io/ <br/>

**Normalized Avatar Synthesis Using StyleGAN and Perceptual Refinement**

| <img src='/Images/normalizedavatar.png' style='height: 225px'>
|:--:|
| Normalized Avatar Synthesis Using StyleGAN and Perceptual Refinement Examples |

Paper: https://arxiv.org/abs/2106.11423 <br/> -->

### Web Applications

**DeepFaceLab: Integrated, flexible and extensible faceswapping framework**

|<img src='/Images/deepfake.png' style='height: 225px'>
|:--:|
| Deepface Labs results from original [paper](https://arxiv.org/pdf/2005.05535.pdf) |

Paper: https://arxiv.org/pdf/2005.05535.pdf <br/>
Code: https://github.com/iperov/DeepFaceLab <br/>

**Ca-GAN: Weakly supervised color aware gan for controllable makeup transfer**

| <img src='/Images/cagan.png' style='height: 225px'>
|:--:|
| Ca-GAN Approach to Transfer Makeup styles |

Paper: https://arxiv.org/abs/2008.10298 <br/>

**GANfolk: Using AI to Create Portraits of Fictional People to Sell as NFTs**
| <img src='/Images/gan_folks.jpeg' style='height: 225px'>
|:--:|
| Example Generated GanFolk Faces |

App: https://towardsdatascience.com/ganfolk-using-ai-to-create-portraits-of-fictional-people-to-sell-as-nfts-6e24f5214ed1 <br/>

Examples of GANFolks from OpenSea:

https://opensea.io/assets/matic/0x2953399124f0cbb46d2cbacd8a89cf0599974963/95949048702184002022994543019454797960309252011183799747181743845102298595329 <br/>

### Virtual Makeup and Accessories Try-on

| <img src='/Images/ffhqtarget.png' style='height: 250px'>
|:--:|
| Target Image |

#### Web Applications

| <img src='/Images/loreal.png' style='height: 200px'><img src='/Images/maybelline.png' style='height: 200px'><img src='/Images/nyx.png' style='height: 200px'> <img src='/Images/eyebuydirect.png' style='height: 200px; width: 200px'>
|:--:|
| Inference results from Loreal, Maybelline, Nyx and EyebuyDirect Website in Order |

**Loreal Virtual Makeup Try-on**

App: https://www.lorealparisusa.com/virtual-try-on-makeup <br/>

**Maybelline Virtual Makeup Try-on**

App: https://www.maybelline.com/virtual-try-on-makeup-tools <br/>

**NyxCosmetics Virtual Makeup Try-on**

App: https://www.nyxcosmetics.com/try-it-on.html <br/>

**EyebuyDirect Virtual Glasses Try-on**

App: https://www.eyebuydirect.com/virtual-try-on <br/>

#### Mobile Applications

| <img src='/Images/FaceApp.JPG' style='height: 200px'><img src='/Images/facelab.JPG' style='height: 200px'><img src='/Images/Facetune2.jpg' style='height: 200px'> <img src='/Images/peachy.PNG' style='height: 200px; width: 200px'><img src='/Images/youcam.JPG' style='height: 200px; width: 200px'>
|:--:|
| Inference results from FaceApp, FaceLab, Facetune2, Peachy and 'YouCam Makeup' iOs Apps in Order |

<!-- **FaceApp**

iOS App: https://apps.apple.com/us/app/faceapp-perfect-face-editor/id1180884341
Android App: https://play.google.com/store/apps/details?id=io.faceapp&hl=tr&gl=US

**FaceLab**

iOS App: https://apps.apple.com/de/app/facelab-gesicht-bearbeiten/id1361012099
Android App: https://play.google.com/store/apps/details?id=com.lyrebirdstudio.facelab&hl=tr&gl=US

**Facetune2**

iOS App: https://apps.apple.com/us/app/facetune2-editor-by-lightricks/id1149994032
Android App: https://play.google.com/store/apps/details?id=com.lightricks.facetune.free&hl=tr&gl=US

**Peachy**

iOS App: https://apps.apple.com/us/app/peachy-gesicht-bearbeiten/id1390423469?l=de

**YouCam Makeup**
iOS App: https://apps.apple.com/de/app/youcam-makeup-selfie-editor/id863844475
Android App: https://play.google.com/store/apps/details?id=com.cyberlink.youcammakeup&hl=tr&gl=US

**Video Face Replacement Using ReFace**
| <img src='/Images/reface-gif.gif' style='height: 300px'>
|:--:|
| Inference results from Reface App |
 -->

**Misterspex Virtual Glasses Try-on**

| <img src='/Images/glasses_spex.png' style='height: 300px'><img src='/Images/glasses_spex2.png' style='height: 300px'>
|:--:|
| Inference results from Misterspex Website |

App: https://www.misterspex.co.uk/l/pg/100508 <br/>

**ZenniOptical Virtual Glasses Try-on**

(ZenniOptical is using the same application for virtual try-on and the results are near identical - 24.06.2022)

App: https://www.zennioptical.com/tryon <br/>

**RealESRGAN Application**

|<img src='/Images/realesrin.png' style='height: 200px'><img src='/Images/realesrout.jpeg' style='height: 200px'>
|:--:|
| RealESR GAN Image Enchancement|

App: https://huggingface.co/spaces/akhaliq/Real-ESRGAN <br/>
Paper: https://arxiv.org/abs/2107.10833 <br/>

**My Heritage Deep Nostalgia**

App: https://www.myheritage.com/deep-nostalgia <br/>

| <img src='/Images/einsteinanim_small_opt.gif' style='height: 250px'>
|:--:|
| MyHeritage Image Animation |

**PhotoMyne Image Restoration**

| <img src='/Images/pymne.jpg' style='height: 250px'>
|:--:|
|PhotoMyne Old Image Restoration App |

App: https://photomyne.com/ <br/>

**Old Photo Restoration**

| <img src='/Images/solvay_half.png' style='height: 250px'>
|:--:|
| Target Image |

### Super Resolution and Deblurring

##### GPEN Face Restoration

| <img src='/Images/solvay_hq_half.png' style='height: 200px'><img src='/Images/vanceai_solvay_half.png' style='height: 200px'><img src='/Images/remini_solvay_half.png' style='height: 200px'>
|:--:|
| Solvay Conference Image Restoration Using GPEN, VanceAI and ReminiAI from left to right. |

App: https://replicate.com/yangxy/gpen <br/>

**VanceAI Image Restoration**

App: https://vanceai.com/old-photo-restoration/ <br/>

**ReminiAI Image Restoration**

App: https://remini.ai/ <br/>

##### Color Enhancement

**ImageColorizer Image Colorizer**

| <img src='/Images/solvay_colored_half.png' style='height: 250px'>
|:--:|
| Solvay Conference Image Colored |

App: https://imagecolorizer.com/ <br/>

**Nvidia Image Restoration**

 <img src='/Images/einstein.gif' style='height: 250px'>

App: https://www.nvidia.com/research/inpainting/index.html <br/>

<!-- **Befunky Cartoonize Photos**

| <img src='/Images/ffhqtarget.png' style='height: 350px'><img src='/Images/befunky.png' style='height: 350px'>
|:--:|
| Image Cartoonized Using Befunky |

App: https://www.befunky.com/features/photo-to-cartoon/ <br/> -->

**BoredApp Generation and CryptoPunks Generation**

| <img src='/Images/ape_small_opt.gif' style='height: 250px'>
|:--:|
| HugginNFT Generator Result [from](https://github.com/AlekseyKorshuk/huggingnft)|

App: https://huggingface.co/huggingnft/boredapeyachtclub <br/>
App: https://huggingface.co/huggingnft/cryptopunks <br/>

<!-- **Cartoonify Photos**

App: https://www.kapwing.com/cartoonify <br/>

(Didn't work at the time: 24.06.2022) -->

**Cartoonize Photos**

App: https://www.cartoonize.net/ <br/>

(Cartoonizing was a pro feature: 24.06.2022)

**Toonify.photos**

| <img src='/Images/arnold.jpg' style='height: 200px'>
|:--:|
| Arnold photo toonified [from](https://toonify.photos/)|

App: https://toonify.photos/ <br/>

---

### Datasets

<br/>

**A Style-Based Generator Architecture for Generative Adversarial Networks**

| <img src='/Images/ffhq_dataset.jpg' style='height: 225px'>
|:--:|
|FFHQ Dataset |

Paper: https://arxiv.org/abs/1812.04948 <br/>
Dataset: https://github.com/NVlabs/ffhq-dataset <br/>

**Celeb-a Dataset**

| <img src='/Images/celeba.png' style='height: 225px'>
|:--:|
|Celeb-a Dataset |

Dataset: https://github.com/tkarras/progressive_growing_of_gans <br/>

**Celeb-a Mask-HQ Dataset**

| <img src='/Images/celebamaskhq.jpeg' style='height: 225px'>
|:--:|
|Celeb-a Mash HQ Dataset |

Dataset: https://github.com/switchablenorms/CelebAMask-HQ <br/>

**Celeb-a Multi-Modal Dataset**

| <img src='/Images/celebamulti.jpg' style='height: 200px'>
|:--:|
|Celeb-a Multi-Modal Dataset |

Dataset: https://github.com/IIGROUP/MM-CelebA-HQ-Dataset <br/>

**FaceForensics++**

| <img src='/Images/forensics.jpg' style='height: 200px'>
|:--:|
|FaceForensics Dataset|

Github: https://github.com/ondyari/FaceForensics <br/>
Data/Description: http://niessnerlab.org/projects/roessler2018faceforensics.html <br/>

**DeepFake Detection Challenge Dataset**

| <img src='/Images/deepfakeds.jpeg' style='height: 250px'>
|:--:|
|DeepFake Detection Challenge Dataset|

Data/Description: https://ai.facebook.com/datasets/dfdc/

**FaceWarehouse: a 3D Facial Expression Database for Visual Computing**

| <img src='/Images/facewh.png' style='height: 250px'><img src='/Images/facewh2.png' style='height: 250px'>
|:--:|
|FaceWarehouseDataset|

Data/Description: http://kunzhou.net/zjugaps/facewarehouse/

**MetFaces**

| <img src='/Images/metfaces.png' style='height: 200px'>
|:--:|
|MetFaces |

Data/Description : https://paperswithcode.com/dataset/metfaces

**CelebDf**

| <img src='/Images/celeb-df.jpg' style='height: 200px'>
|:--:|
|CelebDf |

Data/Description : https://paperswithcode.com/dataset/celeb-df

**LFW (Labeled Faces in the Wild)**

| <img src='/Images/lfw.jpg' style='height: 200px'>
|:--:|
|LFW (Labeled Faces in the Wild) |

Data/Description : https://paperswithcode.com/dataset/lfw

**MegaFace (Retired Data set)**

| <img src='/Images/megaface.png' style='height: 200px'>
|:--:|
|MegaFace (Retired Data set) |

Data/Description : https://paperswithcode.com/dataset/megaface

**VGGFace2 HQ**
| <img src='/Images/vggface.png' style='height: 200px'>
|:--:|
|VGG Face 2 HQ|

Data/Description : https://paperswithcode.com/dataset/vggface2-hq

**ArtBench-10**

(Not a faces data set directly but used with stylegan2 to train conditional image generation models)

| <img src='/Images/art-bench-10.jpg' style='height: 250px'>
|:--:|
|ArtBench-10 |

Data/Description : https://paperswithcode.com/dataset/artbench-10

<!-- 
---

### Neural Network Architectures for Generation of Faces

<br/>

**Analyzing and Improving the Image Quality of StyleGAN**

Paper: https://arxiv.org/abs/1912.04958 <br/>
Code: https://github.com/NVlabs/stylegan2 <br/>

**DeepFaceLab: Integrated, flexible and extensible face-swapping framework**

Paper: https://arxiv.org/abs/2005.05535 <br/>
Code: https://github.com/iperov/DeepFaceLab <br/>

**MyStyle: A Personalized Generative Prior**

Paper: https://arxiv.org/abs/2203.17272 <br/>

**Third Time's the Charm? Image and Video Editing with StyleGAN3**

Paper: https://arxiv.org/abs/2201.13433 <br/>
Code: https://github.com/yuval-alaluf/stylegan3-editing <br/>

---

### Similarity of Faces and Loses For Training

<br/>

**ArcFace: Additive Angular Margin Loss for Deep Face Recognition**

Paper: https://arxiv.org/abs/1801.07698 <br/>

**The Unreasonable Effectiveness of Deep Features as a Perceptual Metric**

Paper: https://arxiv.org/abs/1801.03924 <br/>

**GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium**

Paper: https://arxiv.org/abs/1706.08500 <br/>
Code: https://github.com/NVlabs/stylegan3 <br/>

---

### The Latent Space

<br/>

**StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation**

Paper: https://arxiv.org/abs/2011.12799 <br/>

**Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?-Supplementary Material**

Paper: https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Abdal_Image2StyleGAN_How_to_ICCV_2019_supplemental.pdf <br/>

---

### Editing of Generated Images

<br/>

**StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery**

Paper: https://openaccess.thecvf.com/content/ICCV2021/html/Patashnik_StyleCLIP_Text-Driven_Manipulation_of_StyleGAN_Imagery_ICCV_2021_paper.html <br/>

**Designing an Encoder for StyleGAN Image Manipulation**

Paper: https://arxiv.org/abs/2102.02766 <br/>

**Learning Transferable Visual Models From Natural Language Supervision**

Paper: https://arxiv.org/abs/2103.00020 <br/>

---

### Finding control parameters in the latent space

<br/>

**Pivotal Tuning for Latent-based Editing of Real Images**

Paper: https://arxiv.org/abs/2106.05744 <br/>

**Analyzing and Improving the Image Quality of StyleGAN**

Paper: https://arxiv.org/abs/1912.04958 <br/>
Code: https://github.com/NVlabs/stylegan2 <br/>

---

### Deep Fake

<br/>

**DeepFaceLab: Integrated, flexible and extensible face-swapping framework**

Paper: https://arxiv.org/abs/2005.05535 <br/>
Code: https://github.com/iperov/DeepFaceLab <br/>

---

### Deblurring

<br/>

**GAN Prior Embedded Network for Blind Face Restoration in the Wild**

Paper: https://arxiv.org/abs/2105.06070 <br/>
Code: https://github.com/yangxy/GPEN <br/>

**Towards Real-World Blind Face Restoration with Generative Facial Prior**

Paper: https://arxiv.org/abs/2101.04061 <br/>
Code: https://github.com/TencentARC/GFPGAN <br/>

**Deblurring by Realistic Blurring**

Paper: https://arxiv.org/abs/2004.01860v2 <br/>
Code: https://github.com/HDCVLab/Deblurring-by-Realistic-Blurring <br/>

**DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better**

Paper: https://arxiv.org/abs/1908.03826v1 <br/>
Code: https://github.com/VITA-Group/DeblurGANv2 <br/>

**ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks**

Paper: https://arxiv.org/abs/1809.00219 <br/>
Code: https://github.com/xinntao/ESRGAN <br/>
 -->
